{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data from SQL\n",
    "#https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'houseprices'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'\n",
    "                       .format(postgres_user, postgres_pw, postgres_host,\n",
    "                              postgres_port, postgres_db))\n",
    "\n",
    "df = pd.read_sql_query('SELECT * FROM houseprices', con=engine)\n",
    "\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'mssubclass', 'mszoning', 'lotfrontage', 'lotarea', 'street',\n",
       "       'alley', 'lotshape', 'landcontour', 'utilities', 'lotconfig',\n",
       "       'landslope', 'neighborhood', 'condition1', 'condition2', 'bldgtype',\n",
       "       'housestyle', 'overallqual', 'overallcond', 'yearbuilt', 'yearremodadd',\n",
       "       'roofstyle', 'roofmatl', 'exterior1st', 'exterior2nd', 'masvnrtype',\n",
       "       'masvnrarea', 'exterqual', 'extercond', 'foundation', 'bsmtqual',\n",
       "       'bsmtcond', 'bsmtexposure', 'bsmtfintype1', 'bsmtfinsf1',\n",
       "       'bsmtfintype2', 'bsmtfinsf2', 'bsmtunfsf', 'totalbsmtsf', 'heating',\n",
       "       'heatingqc', 'centralair', 'electrical', 'firstflrsf', 'secondflrsf',\n",
       "       'lowqualfinsf', 'grlivarea', 'bsmtfullbath', 'bsmthalfbath', 'fullbath',\n",
       "       'halfbath', 'bedroomabvgr', 'kitchenabvgr', 'kitchenqual',\n",
       "       'totrmsabvgrd', 'functional', 'fireplaces', 'fireplacequ', 'garagetype',\n",
       "       'garageyrblt', 'garagefinish', 'garagecars', 'garagearea', 'garagequal',\n",
       "       'garagecond', 'paveddrive', 'wooddecksf', 'openporchsf',\n",
       "       'enclosedporch', 'threessnporch', 'screenporch', 'poolarea', 'poolqc',\n",
       "       'fence', 'miscfeature', 'miscval', 'mosold', 'yrsold', 'saletype',\n",
       "       'salecondition', 'saleprice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display original 81 columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2008, 2007, 2006, 2009, 2010], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['yrsold'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding categorical variables and creating correlation matrix\n",
    "one_hot = pd.get_dummies(df, drop_first=True)\n",
    "corr_df = one_hot.corr()\n",
    "\n",
    "#finding and dropping values that have less than 5% correlation in either direction with our target variable to shrink feature space\n",
    "#low_corr = corr_df.loc[abs(corr_df['saleprice']) < .05]\n",
    "#low_corr = low_corr['saleprice'].index\n",
    "#low_corr_list = [x for x in low_corr]\n",
    "\n",
    "df = one_hot#.drop(low_corr_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filling missing values\n",
    "df['lotfrontage'].fillna(df['lotfrontage'].mean(), inplace=True)\n",
    "df['garageyrblt'].fillna(df['yearbuilt'], inplace=True)\n",
    "df['masvnrarea'].fillna(df['masvnrarea'].mean(), inplace=True)\n",
    "\n",
    "#display number of null values\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2289633669486182"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Performing PCA \n",
    "scaled_df = StandardScaler().fit_transform(df)\n",
    "sklearn_pca = PCA(n_components=10)\n",
    "pca_arrays  = sklearn_pca.fit_transform(scaled_df)\n",
    "\n",
    "#checking how much variance is explained using PCA\n",
    "sklearn_pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that with 10 principle components we are only able to explain 33.9% of the variance. For this reason we will not be using PCA in our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1, 0, 4], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['garagecars'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=uint64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['garagearea'].unique()\n",
    "#df['garageyrblt'].unique()\n",
    "df['garagefinish_Unf'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining similar continuous features\n",
    "df['garage'] = df['garagecars'] * df['garagearea'] * df['garageyrblt']\n",
    "df['qual_liv_area'] = df['overallqual'] * df['grlivarea'] \n",
    "df['exter_kitchen_qual'] = df['exterqual_TA'] * df['kitchenqual_TA']\n",
    "\n",
    "drop_list = ['garagecars', 'garagearea', 'garageyrblt', 'overallqual', 'grlivarea']\n",
    "df = df.drop(drop_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qual_liv_area    0.832\n",
       "garage           0.683\n",
       "totalbsmtsf      0.614\n",
       "firstflrsf       0.606\n",
       "exterqual_TA     0.589\n",
       "fullbath         0.561\n",
       "totrmsabvgrd     0.534\n",
       "yearbuilt        0.523\n",
       "kitchenqual_TA   0.519\n",
       "yearremodadd     0.507\n",
       "Name: saleprice, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding 10 features that are most correlated with saleprice in either direction\n",
    "top_10_abs = abs(df.corr()['saleprice']).sort_values(ascending=False)[1:11]\n",
    "top_10_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qual_liv_area</th>\n",
       "      <th>garage</th>\n",
       "      <th>totalbsmtsf</th>\n",
       "      <th>firstflrsf</th>\n",
       "      <th>exterqual_TA</th>\n",
       "      <th>fullbath</th>\n",
       "      <th>totrmsabvgrd</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>kitchenqual_TA</th>\n",
       "      <th>yearremodadd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qual_liv_area</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.596</td>\n",
       "      <td>-0.533</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.365</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>0.411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>garage</th>\n",
       "      <td>0.604</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.491</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>0.411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalbsmtsf</th>\n",
       "      <td>0.556</td>\n",
       "      <td>0.503</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.820</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.391</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>0.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firstflrsf</th>\n",
       "      <td>0.596</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.820</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exterqual_TA</th>\n",
       "      <td>-0.533</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>-0.390</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>-0.589</td>\n",
       "      <td>0.672</td>\n",
       "      <td>-0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullbath</th>\n",
       "      <td>0.630</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.468</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>0.439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totrmsabvgrd</th>\n",
       "      <td>0.719</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.410</td>\n",
       "      <td>-0.242</td>\n",
       "      <td>0.555</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearbuilt</th>\n",
       "      <td>0.365</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.282</td>\n",
       "      <td>-0.589</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.096</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>0.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kitchenqual_TA</th>\n",
       "      <td>-0.466</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>0.672</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearremodadd</th>\n",
       "      <td>0.411</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-0.565</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.593</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                qual_liv_area  garage  totalbsmtsf  firstflrsf  exterqual_TA  \\\n",
       "qual_liv_area           1.000   0.604        0.556       0.596        -0.533   \n",
       "garage                  0.604   1.000        0.503       0.500        -0.494   \n",
       "totalbsmtsf             0.556   0.503        1.000       0.820        -0.390   \n",
       "firstflrsf              0.596   0.500        0.820       1.000        -0.313   \n",
       "exterqual_TA           -0.533  -0.494       -0.390      -0.313         1.000   \n",
       "fullbath                0.630   0.444        0.324       0.381        -0.466   \n",
       "totrmsabvgrd            0.719   0.392        0.286       0.410        -0.242   \n",
       "yearbuilt               0.365   0.491        0.391       0.282        -0.589   \n",
       "kitchenqual_TA         -0.466  -0.411       -0.311      -0.274         0.672   \n",
       "yearremodadd            0.411   0.411        0.291       0.240        -0.565   \n",
       "\n",
       "                fullbath  totrmsabvgrd  yearbuilt  kitchenqual_TA  \\\n",
       "qual_liv_area      0.630         0.719      0.365          -0.466   \n",
       "garage             0.444         0.392      0.491          -0.411   \n",
       "totalbsmtsf        0.324         0.286      0.391          -0.311   \n",
       "firstflrsf         0.381         0.410      0.282          -0.274   \n",
       "exterqual_TA      -0.466        -0.242     -0.589           0.672   \n",
       "fullbath           1.000         0.555      0.468          -0.419   \n",
       "totrmsabvgrd       0.555         1.000      0.096          -0.210   \n",
       "yearbuilt          0.468         0.096      1.000          -0.460   \n",
       "kitchenqual_TA    -0.419        -0.210     -0.460           1.000   \n",
       "yearremodadd       0.439         0.192      0.593          -0.577   \n",
       "\n",
       "                yearremodadd  \n",
       "qual_liv_area          0.411  \n",
       "garage                 0.411  \n",
       "totalbsmtsf            0.291  \n",
       "firstflrsf             0.240  \n",
       "exterqual_TA          -0.565  \n",
       "fullbath               0.439  \n",
       "totrmsabvgrd           0.192  \n",
       "yearbuilt              0.593  \n",
       "kitchenqual_TA        -0.577  \n",
       "yearremodadd           1.000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving names of features to list\n",
    "pred_features = list(top_10_abs.index)\n",
    "\n",
    "#Examining correlation between predictive features\n",
    "top_10_abs_corr = df[top_10_abs.index].corr()\n",
    "top_10_abs_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = sns.heatmap(\n",
    "    top_10_abs_corr, \n",
    "    cmap=sns.diverging_palette(20, 220), \n",
    "    square=True,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    linewidths=.5).set_title('Predictive Feature Correlation Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above correlation matrix we can see that we encounter a situation where we have three sets of features that have high correlation with eachother. We see that qual_liv_area and totrmsabvgrd, firstflrsf and totalbsmtsf, and exterqual_TA and kitchenqual_TA are all highly correlated (>67%). After itterating through the feature engineering step it is clear that by combining these features results in worse correlation with the target variable in each case. For this reason the lower of each pair will be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qual_liv_area',\n",
       " 'garage',\n",
       " 'totalbsmtsf',\n",
       " 'exterqual_TA',\n",
       " 'fullbath',\n",
       " 'yearbuilt',\n",
       " 'yearremodadd']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping less correlated of each of the highly correlated feature pairs and displaying remainder\n",
    "pred_features = [x for x in pred_features if x not in ('totrmsabvgrd','firstflrsf', 'kitchenqual_TA')]\n",
    "pred_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define target variable\n",
    "Y = df['saleprice']\n",
    "\n",
    "#define predictive variables\n",
    "X = df[pred_features]\n",
    "\n",
    "#splitting data into training and testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>saleprice</td>    <th>  R-squared:         </th> <td>   0.768</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.767</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   548.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 07 Oct 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:00:21</td>     <th>  Log-Likelihood:    </th> <td> -13973.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.796e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1160</td>      <th>  BIC:               </th> <td>2.800e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td> -1.19e+06</td> <td> 1.46e+05</td> <td>   -8.167</td> <td> 0.000</td> <td>-1.48e+06</td> <td>-9.04e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qual_liv_area</th> <td>    8.0825</td> <td>    0.345</td> <td>   23.445</td> <td> 0.000</td> <td>    7.406</td> <td>    8.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garage</th>        <td>    0.0104</td> <td>    0.001</td> <td>    9.810</td> <td> 0.000</td> <td>    0.008</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>totalbsmtsf</th>   <td>   20.6455</td> <td>    3.224</td> <td>    6.404</td> <td> 0.000</td> <td>   14.320</td> <td>   26.971</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exterqual_TA</th>  <td>-1.094e+04</td> <td> 3271.890</td> <td>   -3.344</td> <td> 0.001</td> <td>-1.74e+04</td> <td>-4522.859</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fullbath</th>      <td>-3140.2082</td> <td> 2742.379</td> <td>   -1.145</td> <td> 0.252</td> <td>-8520.786</td> <td> 2240.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearbuilt</th>     <td>  303.4338</td> <td>   52.005</td> <td>    5.835</td> <td> 0.000</td> <td>  201.400</td> <td>  405.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearremodadd</th>  <td>  334.6035</td> <td>   71.746</td> <td>    4.664</td> <td> 0.000</td> <td>  193.838</td> <td>  475.369</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>922.473</td> <th>  Durbin-Watson:     </th>  <td>   1.905</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>152377.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-2.782</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>58.678</td>  <th>  Cond. No.          </th>  <td>3.17e+08</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.17e+08. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              saleprice   R-squared:                       0.768\n",
       "Model:                            OLS   Adj. R-squared:                  0.767\n",
       "Method:                 Least Squares   F-statistic:                     548.6\n",
       "Date:                Mon, 07 Oct 2019   Prob (F-statistic):               0.00\n",
       "Time:                        20:00:21   Log-Likelihood:                -13973.\n",
       "No. Observations:                1168   AIC:                         2.796e+04\n",
       "Df Residuals:                    1160   BIC:                         2.800e+04\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const          -1.19e+06   1.46e+05     -8.167      0.000   -1.48e+06   -9.04e+05\n",
       "qual_liv_area     8.0825      0.345     23.445      0.000       7.406       8.759\n",
       "garage            0.0104      0.001      9.810      0.000       0.008       0.012\n",
       "totalbsmtsf      20.6455      3.224      6.404      0.000      14.320      26.971\n",
       "exterqual_TA  -1.094e+04   3271.890     -3.344      0.001   -1.74e+04   -4522.859\n",
       "fullbath      -3140.2082   2742.379     -1.145      0.252   -8520.786    2240.370\n",
       "yearbuilt       303.4338     52.005      5.835      0.000     201.400     405.467\n",
       "yearremodadd    334.6035     71.746      4.664      0.000     193.838     475.369\n",
       "==============================================================================\n",
       "Omnibus:                      922.473   Durbin-Watson:                   1.905\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           152377.248\n",
       "Skew:                          -2.782   Prob(JB):                         0.00\n",
       "Kurtosis:                      58.678   Cond. No.                     3.17e+08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.17e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding constant\n",
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "#fitting linear regression model to data\n",
    "OLS_model_train = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "#printing summary statistics\n",
    "OLS_model_train.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>saleprice</td>    <th>  R-squared:         </th> <td>   0.895</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.893</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   347.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 07 Oct 2019</td> <th>  Prob (F-statistic):</th> <td>3.06e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:00:21</td>     <th>  Log-Likelihood:    </th> <td> -3387.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   292</td>      <th>  AIC:               </th> <td>   6791.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   284</td>      <th>  BIC:               </th> <td>   6821.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>-1.083e+06</td> <td> 2.15e+05</td> <td>   -5.042</td> <td> 0.000</td> <td>-1.51e+06</td> <td> -6.6e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qual_liv_area</th> <td>   12.3120</td> <td>    0.526</td> <td>   23.427</td> <td> 0.000</td> <td>   11.278</td> <td>   13.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garage</th>        <td>    0.0054</td> <td>    0.002</td> <td>    3.190</td> <td> 0.002</td> <td>    0.002</td> <td>    0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>totalbsmtsf</th>   <td>   35.3588</td> <td>    4.660</td> <td>    7.587</td> <td> 0.000</td> <td>   26.186</td> <td>   44.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exterqual_TA</th>  <td> 4650.3844</td> <td> 4551.573</td> <td>    1.022</td> <td> 0.308</td> <td>-4308.714</td> <td> 1.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fullbath</th>      <td>-1.402e+04</td> <td> 4380.462</td> <td>   -3.201</td> <td> 0.002</td> <td>-2.26e+04</td> <td>-5401.572</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearbuilt</th>     <td>  358.1435</td> <td>   87.412</td> <td>    4.097</td> <td> 0.000</td> <td>  186.086</td> <td>  530.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearremodadd</th>  <td>  206.7091</td> <td>  106.741</td> <td>    1.937</td> <td> 0.054</td> <td>   -3.395</td> <td>  416.814</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>21.062</td> <th>  Durbin-Watson:     </th> <td>   1.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  54.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.272</td> <th>  Prob(JB):          </th> <td>1.52e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.044</td> <th>  Cond. No.          </th> <td>3.17e+08</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.17e+08. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              saleprice   R-squared:                       0.895\n",
       "Model:                            OLS   Adj. R-squared:                  0.893\n",
       "Method:                 Least Squares   F-statistic:                     347.6\n",
       "Date:                Mon, 07 Oct 2019   Prob (F-statistic):          3.06e-135\n",
       "Time:                        20:00:21   Log-Likelihood:                -3387.6\n",
       "No. Observations:                 292   AIC:                             6791.\n",
       "Df Residuals:                     284   BIC:                             6821.\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const         -1.083e+06   2.15e+05     -5.042      0.000   -1.51e+06    -6.6e+05\n",
       "qual_liv_area    12.3120      0.526     23.427      0.000      11.278      13.346\n",
       "garage            0.0054      0.002      3.190      0.002       0.002       0.009\n",
       "totalbsmtsf      35.3588      4.660      7.587      0.000      26.186      44.532\n",
       "exterqual_TA   4650.3844   4551.573      1.022      0.308   -4308.714    1.36e+04\n",
       "fullbath      -1.402e+04   4380.462     -3.201      0.002   -2.26e+04   -5401.572\n",
       "yearbuilt       358.1435     87.412      4.097      0.000     186.086     530.201\n",
       "yearremodadd    206.7091    106.741      1.937      0.054      -3.395     416.814\n",
       "==============================================================================\n",
       "Omnibus:                       21.062   Durbin-Watson:                   1.884\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               54.429\n",
       "Skew:                           0.272   Prob(JB):                     1.52e-12\n",
       "Kurtosis:                       5.044   Cond. No.                     3.17e+08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.17e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding constant\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "#fitting linear regression model to data\n",
    "OLS_model_test = sm.OLS(y_test, X_test).fit()\n",
    "\n",
    "#printing summary statistics\n",
    "OLS_model_test.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we testing this model on the traning data we found an adjusted R-squared value of .836, additionally we saw that all of our parameters were statistically significant by examining their p-values, which were all less than 0.05. However when we test this model on the testing data we can see a significant drop in performance. We see that our adjust R-squared drops to .644. This is an indication that our model is overfit. We can also see that on the testing data we have p-values that exceed our 0.10 threshold. This can be seen for the totalbsmtsf and fullbath features which both are now statistically insignificant. To improve this model we could drop these features and reexamine our test statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 77829569.39578474\n",
      "R-squared of the model in training set is: 0.6653398111968482\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.705311577986093\n",
      "Mean absolute error of the prediction is: 28048.702060267216\n",
      "Mean squared error of the prediction is: 1969866281.5180519\n",
      "Root mean squared error of the prediction is: 44383.1756583286\n",
      "Mean absolute percentage error of the prediction is: 17.57066270693426\n"
     ]
    }
   ],
   "source": [
    "lasso_cv = LassoCV(cv=10)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = lasso_cv.predict(X_train)\n",
    "y_preds_test = lasso_cv.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(lasso_cv.alpha_))\n",
    "print(\"R-squared of the model in training set is: {}\".format(lasso_cv.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(lasso_cv.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 10.0\n",
      "R-squared of the model in training set is: 0.7679949406015176\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.8527319118030798\n",
      "Mean absolute error of the prediction is: 20171.77944646849\n",
      "Mean squared error of the prediction is: 984424292.275213\n",
      "Root mean squared error of the prediction is: 31375.53652569487\n",
      "Mean absolute percentage error of the prediction is: 11.973080746655134\n"
     ]
    }
   ],
   "source": [
    "ridge_cv = RidgeCV(cv=10)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = ridge_cv.predict(X_train)\n",
    "y_preds_test = ridge_cv.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(ridge_cv.alpha_))\n",
    "print(\"R-squared of the model in training set is: {}\".format(ridge_cv.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(ridge_cv.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 155659138.79156917\n",
      "R-squared of the model in training set is: 0.515102734434085\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.514281801193931\n",
      "Mean absolute error of the prediction is: 35871.7017885568\n",
      "Mean squared error of the prediction is: 3246818777.639672\n",
      "Root mean squared error of the prediction is: 56980.86325811212\n",
      "Mean absolute percentage error of the prediction is: 22.31794847982364\n"
     ]
    }
   ],
   "source": [
    "elasticnet_cv = ElasticNetCV(cv=10)\n",
    "\n",
    "elasticnet_cv.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = elasticnet_cv.predict(X_train)\n",
    "y_preds_test = elasticnet_cv.predict(X_test)\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(elasticnet_cv.alpha_))\n",
    "print(\"R-squared of the model in training set is: {}\".format(elasticnet_cv.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(elasticnet_cv.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping features and retesting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping features that were not statistically significant in test set\n",
    "pred_features = [x for x in pred_features if x not in ('totalbsmtsf','fullbath')]\n",
    "\n",
    "#define target variable\n",
    "Y = df['saleprice']\n",
    "\n",
    "#define predictive variables\n",
    "X = df[pred_features]\n",
    "\n",
    "#splitting data into training and testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS Model V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>saleprice</td>    <th>  R-squared:         </th> <td>   0.765</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.764</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   758.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 07 Oct 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:00:21</td>     <th>  Log-Likelihood:    </th> <td> -13999.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.801e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1162</td>      <th>  BIC:               </th> <td>2.804e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>-1.169e+06</td> <td> 1.44e+05</td> <td>   -8.140</td> <td> 0.000</td> <td>-1.45e+06</td> <td>-8.87e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qual_liv_area</th> <td>    9.0720</td> <td>    0.300</td> <td>   30.271</td> <td> 0.000</td> <td>    8.484</td> <td>    9.660</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garage</th>        <td>    0.0110</td> <td>    0.001</td> <td>   10.332</td> <td> 0.000</td> <td>    0.009</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exterqual_TA</th>  <td>-9944.5973</td> <td> 3334.207</td> <td>   -2.983</td> <td> 0.003</td> <td>-1.65e+04</td> <td>-3402.857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearbuilt</th>     <td>  333.5311</td> <td>   51.878</td> <td>    6.429</td> <td> 0.000</td> <td>  231.745</td> <td>  435.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearremodadd</th>  <td>  297.2903</td> <td>   72.936</td> <td>    4.076</td> <td> 0.000</td> <td>  154.188</td> <td>  440.392</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>681.545</td> <th>  Durbin-Watson:     </th> <td>   2.034</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>75003.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.742</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>42.103</td>  <th>  Cond. No.          </th> <td>3.09e+08</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.09e+08. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              saleprice   R-squared:                       0.765\n",
       "Model:                            OLS   Adj. R-squared:                  0.764\n",
       "Method:                 Least Squares   F-statistic:                     758.2\n",
       "Date:                Mon, 07 Oct 2019   Prob (F-statistic):               0.00\n",
       "Time:                        20:00:21   Log-Likelihood:                -13999.\n",
       "No. Observations:                1168   AIC:                         2.801e+04\n",
       "Df Residuals:                    1162   BIC:                         2.804e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const         -1.169e+06   1.44e+05     -8.140      0.000   -1.45e+06   -8.87e+05\n",
       "qual_liv_area     9.0720      0.300     30.271      0.000       8.484       9.660\n",
       "garage            0.0110      0.001     10.332      0.000       0.009       0.013\n",
       "exterqual_TA  -9944.5973   3334.207     -2.983      0.003   -1.65e+04   -3402.857\n",
       "yearbuilt       333.5311     51.878      6.429      0.000     231.745     435.317\n",
       "yearremodadd    297.2903     72.936      4.076      0.000     154.188     440.392\n",
       "==============================================================================\n",
       "Omnibus:                      681.545   Durbin-Watson:                   2.034\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            75003.034\n",
       "Skew:                          -1.742   Prob(JB):                         0.00\n",
       "Kurtosis:                      42.103   Cond. No.                     3.09e+08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.09e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding constant\n",
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "#fitting linear regression model to data\n",
    "OLS_model_train = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "#printing summary statistics\n",
    "OLS_model_train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>saleprice</td>    <th>  R-squared:         </th> <td>   0.828</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.825</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   274.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 07 Oct 2019</td> <th>  Prob (F-statistic):</th> <td>6.90e-107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:00:21</td>     <th>  Log-Likelihood:    </th> <td> -3441.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   292</td>      <th>  AIC:               </th> <td>   6894.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   286</td>      <th>  BIC:               </th> <td>   6916.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>-1.074e+06</td> <td> 2.49e+05</td> <td>   -4.315</td> <td> 0.000</td> <td>-1.56e+06</td> <td>-5.84e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qual_liv_area</th> <td>   10.2535</td> <td>    0.461</td> <td>   22.221</td> <td> 0.000</td> <td>    9.345</td> <td>   11.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garage</th>        <td>    0.0113</td> <td>    0.002</td> <td>    5.667</td> <td> 0.000</td> <td>    0.007</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exterqual_TA</th>  <td>-1291.9348</td> <td> 5451.167</td> <td>   -0.237</td> <td> 0.813</td> <td> -1.2e+04</td> <td> 9437.561</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearbuilt</th>     <td>  436.2205</td> <td>   90.579</td> <td>    4.816</td> <td> 0.000</td> <td>  257.935</td> <td>  614.506</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearremodadd</th>  <td>  137.0475</td> <td>  123.909</td> <td>    1.106</td> <td> 0.270</td> <td> -106.841</td> <td>  380.936</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>67.504</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 318.966</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.851</td> <th>  Prob(JB):          </th> <td>5.46e-70</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.829</td> <th>  Cond. No.          </th> <td>2.97e+08</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.97e+08. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              saleprice   R-squared:                       0.828\n",
       "Model:                            OLS   Adj. R-squared:                  0.825\n",
       "Method:                 Least Squares   F-statistic:                     274.5\n",
       "Date:                Mon, 07 Oct 2019   Prob (F-statistic):          6.90e-107\n",
       "Time:                        20:00:21   Log-Likelihood:                -3441.0\n",
       "No. Observations:                 292   AIC:                             6894.\n",
       "Df Residuals:                     286   BIC:                             6916.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const         -1.074e+06   2.49e+05     -4.315      0.000   -1.56e+06   -5.84e+05\n",
       "qual_liv_area    10.2535      0.461     22.221      0.000       9.345      11.162\n",
       "garage            0.0113      0.002      5.667      0.000       0.007       0.015\n",
       "exterqual_TA  -1291.9348   5451.167     -0.237      0.813    -1.2e+04    9437.561\n",
       "yearbuilt       436.2205     90.579      4.816      0.000     257.935     614.506\n",
       "yearremodadd    137.0475    123.909      1.106      0.270    -106.841     380.936\n",
       "==============================================================================\n",
       "Omnibus:                       67.504   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              318.966\n",
       "Skew:                           0.851   Prob(JB):                     5.46e-70\n",
       "Kurtosis:                       7.829   Cond. No.                     2.97e+08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.97e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding constant\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "#fitting linear regression model to data\n",
    "OLS_model_test = sm.OLS(y_test, X_test).fit()\n",
    "\n",
    "#printing summary statistics\n",
    "OLS_model_test.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 81029526.33611512\n",
      "R-squared of the model in training set is: 0.6707167118221848\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.6950199706482358\n",
      "Mean absolute error of the prediction is: 27741.191217411088\n",
      "Mean squared error of the prediction is: 1782027329.8441577\n",
      "Root mean squared error of the prediction is: 42214.06554507819\n",
      "Mean absolute percentage error of the prediction is: 17.167698903572383\n"
     ]
    }
   ],
   "source": [
    "lasso_cv = LassoCV(cv=10)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = lasso_cv.predict(X_train)\n",
    "y_preds_test = lasso_cv.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(lasso_cv.alpha_))\n",
    "print(\"R-squared of the model in training set is: {}\".format(lasso_cv.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(lasso_cv.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 10.0\n",
      "R-squared of the model in training set is: 0.7653916422307315\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.8186301956126757\n",
      "Mean absolute error of the prediction is: 22194.04589234656\n",
      "Mean squared error of the prediction is: 1059761024.0699233\n",
      "Root mean squared error of the prediction is: 32553.97094165201\n",
      "Mean absolute percentage error of the prediction is: 12.989637494419009\n"
     ]
    }
   ],
   "source": [
    "ridge_cv = RidgeCV(cv=10)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = ridge_cv.predict(X_train)\n",
    "y_preds_test = ridge_cv.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(ridge_cv.alpha_))\n",
    "print(\"R-squared of the model in training set is: {}\".format(ridge_cv.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(ridge_cv.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet Regression V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 162059052.67223057\n",
      "R-squared of the model in training set is: 0.5180067475009595\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.484835458376881\n",
      "Mean absolute error of the prediction is: 35550.965427010306\n",
      "Mean squared error of the prediction is: 3010155433.7519298\n",
      "Root mean squared error of the prediction is: 54864.883429675945\n",
      "Mean absolute percentage error of the prediction is: 21.97811730684306\n"
     ]
    }
   ],
   "source": [
    "elasticnet_cv = ElasticNetCV(cv=10)\n",
    "\n",
    "elasticnet_cv.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = elasticnet_cv.predict(X_train)\n",
    "y_preds_test = elasticnet_cv.predict(X_test)\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(elasticnet_cv.alpha_))\n",
    "print(\"R-squared of the model in training set is: {}\".format(elasticnet_cv.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(elasticnet_cv.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow_df = pd.read_csv('State_time_series.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13212, 82)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zillow_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brining in additional data for Iowa in the time span that we were examining \n",
    "zillow_df = zillow_df.loc[zillow_df['RegionName'] == 'Iowa']\n",
    "\n",
    "zillow_df['Date'] = pd.to_datetime(zillow_df['Date'])\n",
    "zillow_data = zillow_df.loc[(zillow_df['Date'] >= '2006-01-01') & (zillow_df['Date'] <= '2010-01-01')]\n",
    "zillow_data = zillow_data[['Date', 'PctOfHomesDecreasingInValues_AllHomes', 'PctOfHomesIncreasingInValues_AllHomes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a column of values calculated from mean of mean of state home value increase + decrease by month\n",
    "unique_yr = df['yrsold'].unique()\n",
    "\n",
    "increase = []\n",
    "decrease = []\n",
    "\n",
    "for year in unique_yr:\n",
    "    year_start = zillow_data['Date'] >= pd.to_datetime(str(year-1)+'-12-31')\n",
    "    year_end = zillow_data['Date'] <= pd.to_datetime(str(year)+'-12-31')\n",
    "    means = zillow_data.loc[(year_start) & (year_end)].mean()\n",
    "    df.loc[df['yrsold'] == year, 'PctHomesIncValue'] = means[0]\n",
    "    df.loc[df['yrsold'] == year, 'PctHomesDecValue'] = means[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PctHomesIncValue</th>\n",
       "      <th>PctHomesDecValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.518</td>\n",
       "      <td>43.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.203</td>\n",
       "      <td>48.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.518</td>\n",
       "      <td>43.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.838</td>\n",
       "      <td>57.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.518</td>\n",
       "      <td>43.525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PctHomesIncValue  PctHomesDecValue\n",
       "0            43.518            43.525\n",
       "1            38.203            48.202\n",
       "2            43.518            43.525\n",
       "3            30.838            57.300\n",
       "4            43.518            43.525"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['PctHomesIncValue', 'PctHomesDecValue']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding features from zillow dataset\n",
    "pred_features.append('PctHomesIncValue')\n",
    "pred_features.append('PctHomesDecValue')\n",
    "\n",
    "#define target variable\n",
    "Y = df['saleprice']\n",
    "\n",
    "#define predictive variables\n",
    "X = df[pred_features]\n",
    "\n",
    "#splitting data into training and testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS Model V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>saleprice</td>    <th>  R-squared:         </th> <td>   0.792</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.791</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   632.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 07 Oct 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:00:46</td>     <th>  Log-Likelihood:    </th> <td> -13926.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th> <td>2.787e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1160</td>      <th>  BIC:               </th> <td>2.791e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td>-1.115e+06</td> <td> 1.49e+05</td> <td>   -7.498</td> <td> 0.000</td> <td>-1.41e+06</td> <td>-8.23e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qual_liv_area</th>    <td>    9.9505</td> <td>    0.280</td> <td>   35.587</td> <td> 0.000</td> <td>    9.402</td> <td>   10.499</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garage</th>           <td>    0.0099</td> <td>    0.001</td> <td>    9.565</td> <td> 0.000</td> <td>    0.008</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exterqual_TA</th>     <td>-6234.0423</td> <td> 3136.516</td> <td>   -1.988</td> <td> 0.047</td> <td>-1.24e+04</td> <td>  -80.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearbuilt</th>        <td>  376.6849</td> <td>   49.751</td> <td>    7.571</td> <td> 0.000</td> <td>  279.074</td> <td>  474.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearremodadd</th>     <td>  219.5094</td> <td>   70.006</td> <td>    3.136</td> <td> 0.002</td> <td>   82.157</td> <td>  356.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PctHomesIncValue</th> <td>  -63.4290</td> <td>  741.377</td> <td>   -0.086</td> <td> 0.932</td> <td>-1518.019</td> <td> 1391.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PctHomesDecValue</th> <td>  167.9176</td> <td>  626.172</td> <td>    0.268</td> <td> 0.789</td> <td>-1060.640</td> <td> 1396.475</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>678.106</td> <th>  Durbin-Watson:     </th>  <td>   2.011</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>109244.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.621</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>50.268</td>  <th>  Cond. No.          </th>  <td>3.34e+08</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.34e+08. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              saleprice   R-squared:                       0.792\n",
       "Model:                            OLS   Adj. R-squared:                  0.791\n",
       "Method:                 Least Squares   F-statistic:                     632.8\n",
       "Date:                Mon, 07 Oct 2019   Prob (F-statistic):               0.00\n",
       "Time:                        20:00:46   Log-Likelihood:                -13926.\n",
       "No. Observations:                1168   AIC:                         2.787e+04\n",
       "Df Residuals:                    1160   BIC:                         2.791e+04\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const            -1.115e+06   1.49e+05     -7.498      0.000   -1.41e+06   -8.23e+05\n",
       "qual_liv_area        9.9505      0.280     35.587      0.000       9.402      10.499\n",
       "garage               0.0099      0.001      9.565      0.000       0.008       0.012\n",
       "exterqual_TA     -6234.0423   3136.516     -1.988      0.047   -1.24e+04     -80.162\n",
       "yearbuilt          376.6849     49.751      7.571      0.000     279.074     474.296\n",
       "yearremodadd       219.5094     70.006      3.136      0.002      82.157     356.861\n",
       "PctHomesIncValue   -63.4290    741.377     -0.086      0.932   -1518.019    1391.161\n",
       "PctHomesDecValue   167.9176    626.172      0.268      0.789   -1060.640    1396.475\n",
       "==============================================================================\n",
       "Omnibus:                      678.106   Durbin-Watson:                   2.011\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           109244.697\n",
       "Skew:                          -1.621   Prob(JB):                         0.00\n",
       "Kurtosis:                      50.268   Cond. No.                     3.34e+08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.34e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding constant\n",
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "#fitting linear regression model to data\n",
    "OLS_model_train = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "#printing summary statistics\n",
    "OLS_model_train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>saleprice</td>    <th>  R-squared:         </th> <td>   0.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.716</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   105.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 07 Oct 2019</td> <th>  Prob (F-statistic):</th> <td>2.51e-75</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:01:03</td>     <th>  Log-Likelihood:    </th> <td> -3511.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   292</td>      <th>  AIC:               </th> <td>   7038.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   284</td>      <th>  BIC:               </th> <td>   7067.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>            <td>-1.164e+06</td> <td> 3.25e+05</td> <td>   -3.585</td> <td> 0.000</td> <td> -1.8e+06</td> <td>-5.25e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qual_liv_area</th>    <td>    6.9663</td> <td>    0.617</td> <td>   11.294</td> <td> 0.000</td> <td>    5.752</td> <td>    8.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>garage</th>           <td>    0.0153</td> <td>    0.002</td> <td>    6.897</td> <td> 0.000</td> <td>    0.011</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exterqual_TA</th>     <td>-1.618e+04</td> <td> 6968.967</td> <td>   -2.322</td> <td> 0.021</td> <td>-2.99e+04</td> <td>-2463.676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearbuilt</th>        <td>  223.3139</td> <td>  109.139</td> <td>    2.046</td> <td> 0.042</td> <td>    8.490</td> <td>  438.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yearremodadd</th>     <td>  457.3761</td> <td>  149.228</td> <td>    3.065</td> <td> 0.002</td> <td>  163.642</td> <td>  751.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PctHomesIncValue</th> <td>-1064.7021</td> <td> 1662.299</td> <td>   -0.640</td> <td> 0.522</td> <td>-4336.691</td> <td> 2207.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PctHomesDecValue</th> <td>-1013.2538</td> <td> 1396.628</td> <td>   -0.725</td> <td> 0.469</td> <td>-3762.310</td> <td> 1735.803</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>141.179</td> <th>  Durbin-Watson:     </th> <td>   2.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3592.895</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.374</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19.963</td>  <th>  Cond. No.          </th> <td>3.26e+08</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.26e+08. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              saleprice   R-squared:                       0.723\n",
       "Model:                            OLS   Adj. R-squared:                  0.716\n",
       "Method:                 Least Squares   F-statistic:                     105.8\n",
       "Date:                Mon, 07 Oct 2019   Prob (F-statistic):           2.51e-75\n",
       "Time:                        20:01:03   Log-Likelihood:                -3511.0\n",
       "No. Observations:                 292   AIC:                             7038.\n",
       "Df Residuals:                     284   BIC:                             7067.\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "const            -1.164e+06   3.25e+05     -3.585      0.000    -1.8e+06   -5.25e+05\n",
       "qual_liv_area        6.9663      0.617     11.294      0.000       5.752       8.180\n",
       "garage               0.0153      0.002      6.897      0.000       0.011       0.020\n",
       "exterqual_TA     -1.618e+04   6968.967     -2.322      0.021   -2.99e+04   -2463.676\n",
       "yearbuilt          223.3139    109.139      2.046      0.042       8.490     438.138\n",
       "yearremodadd       457.3761    149.228      3.065      0.002     163.642     751.110\n",
       "PctHomesIncValue -1064.7021   1662.299     -0.640      0.522   -4336.691    2207.287\n",
       "PctHomesDecValue -1013.2538   1396.628     -0.725      0.469   -3762.310    1735.803\n",
       "==============================================================================\n",
       "Omnibus:                      141.179   Durbin-Watson:                   2.016\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3592.895\n",
       "Skew:                          -1.374   Prob(JB):                         0.00\n",
       "Kurtosis:                      19.963   Cond. No.                     3.26e+08\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.26e+08. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding constant\n",
    "X_test = sm.add_constant(X_test)\n",
    "\n",
    "#fitting linear regression model to data\n",
    "OLS_model_test = sm.OLS(y_test, X_test).fit()\n",
    "\n",
    "#printing summary statistics\n",
    "OLS_model_test.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 77457629.65233849\n",
      "R-squared of the model in training set is: 0.7065794063350719\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.6638150071714788\n",
      "Mean absolute error of the prediction is: 29520.83013555863\n",
      "Mean squared error of the prediction is: 1972914854.558256\n",
      "Root mean squared error of the prediction is: 44417.50617220935\n",
      "Mean absolute percentage error of the prediction is: 18.766162266983567\n"
     ]
    }
   ],
   "source": [
    "lasso_cv = LassoCV(cv=10)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = lasso_cv.predict(X_train)\n",
    "y_preds_test = lasso_cv.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(lasso_cv.alpha_))\n",
    "print(\"R-squared of the model in training set is: {}\".format(lasso_cv.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(lasso_cv.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 10.0\n",
      "R-squared of the model in training set is: 0.7924651359912909\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.6972222093268282\n",
      "Mean absolute error of the prediction is: 25815.990662347616\n",
      "Mean squared error of the prediction is: 1776863374.6067455\n",
      "Root mean squared error of the prediction is: 42152.85725317734\n",
      "Mean absolute percentage error of the prediction is: 15.50629833401214\n"
     ]
    }
   ],
   "source": [
    "ridge_cv = RidgeCV(cv=10)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = ridge_cv.predict(X_train)\n",
    "y_preds_test = ridge_cv.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(ridge_cv.alpha_))\n",
    "print(\"R-squared of the model in training set is: {}\".format(ridge_cv.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(ridge_cv.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet Regression V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 154915259.30467668\n",
      "R-squared of the model in training set is: 0.5227179407351656\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.5193926400650948\n",
      "Mean absolute error of the prediction is: 37110.096767087045\n",
      "Mean squared error of the prediction is: 2820463196.9079313\n",
      "Root mean squared error of the prediction is: 53108.033261531455\n",
      "Mean absolute percentage error of the prediction is: 23.867680511816072\n"
     ]
    }
   ],
   "source": [
    "elasticnet_cv = ElasticNetCV(cv=10)\n",
    "\n",
    "elasticnet_cv.fit(X_train, y_train)\n",
    "\n",
    "# We are making predictions here\n",
    "y_preds_train = elasticnet_cv.predict(X_train)\n",
    "y_preds_test = elasticnet_cv.predict(X_test)\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(elasticnet_cv.alpha_))\n",
    "print(\"R-squared of the model in training set is: {}\".format(elasticnet_cv.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(elasticnet_cv.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding additional data from our second dataset did not improve our prediction accuracy. When the model including these new features was tested it was found that these new features were not statistically significant. It is possible that the method in which they were implimented was over simplified. In this case I used mean values calculated from the values reported by the month and assigned them to the original dataframe according to the year in which the house was sold. It is possible that we could have improved prediction if this model is fixed to have the monthly values assigned to the dataframe based on the month the house was sold instead of using the mean value for the year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
