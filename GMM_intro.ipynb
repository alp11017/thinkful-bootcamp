{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'heartdisease'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(postgres_user, postgres_pw, postgres_host,\n",
    "                                                           postgres_port, postgres_db))\n",
    "\n",
    "df = pd.read_sql_query('SELECT * FROM heartdisease', con=engine)\n",
    "\n",
    "engine.dispose()\n",
    "\n",
    "# Define the features and the outcome\n",
    "X = df.iloc[:, :13]\n",
    "y = df.iloc[:, 13]\n",
    "\n",
    "# Replace missing values (marked by ?) with a 0\n",
    "X = X.replace(to_replace='?', value=0)\n",
    "\n",
    "# Binarize y so that 1 means heart disease diagnosis and 0 means no diagnosis\n",
    "y = np.where(y > 0, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply GMM to the heart disease data by setting n_components=2. Get ARI and silhoutte scores for your solution and compare it with those of the k-means and hierarchical clustering solutions that you implemented in the assignments of the previous checkpoints. Which algorithm does perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardizing X values\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "\n",
    "#Define agglomerative clustering \n",
    "gmm_cluster = GaussianMixture(n_components=2, random_state=123)\n",
    "\n",
    "#Fit model\n",
    "clusters = gmm_cluster.fit_predict(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjusted rand index: 0.18389186035089963\n",
      "silhouette score: 0.13628813153331445\n"
     ]
    }
   ],
   "source": [
    "ari = metrics.adjusted_rand_score(y, clusters)\n",
    "sil_score = metrics.silhouette_score(X_std, clusters, metric='euclidean')\n",
    "\n",
    "print('adjusted rand index: {}'.format(ari))\n",
    "print('silhouette score: {}'.format(sil_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMM scores lower than both k-means and hierarchical clustering in terms of ARI and silhouette scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMM implementation of scikit-learn has a parameter called covariance_type. This parameter determines the type of covariance parameters to use. Specifically, there are four types you can specify:\n",
    "\n",
    "    full: This is the default. Each component has its own general covariance matrix.\n",
    "    tied: All components share the same general covariance matrix.\n",
    "    diag: Each component has its own diagonal covariance matrix.\n",
    "    spherical: Each component has its own single variance.\n",
    "\n",
    "Try all of these. Which one does perform better in terms of ARI and silhouette scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance type: full\n",
      "adjusted rand index: 0.18389186035089963\n",
      "silhouette score: 0.13628813153331445\n",
      "\n",
      "\n",
      "covariance type: tied\n",
      "adjusted rand index: 0.18389186035089963\n",
      "silhouette score: 0.13628813153331445\n",
      "\n",
      "\n",
      "covariance type: diag\n",
      "adjusted rand index: 0.18389186035089963\n",
      "silhouette score: 0.13628813153331445\n",
      "\n",
      "\n",
      "covariance type: spherical\n",
      "adjusted rand index: 0.20765243525722465\n",
      "silhouette score: 0.12468753110276873\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "covariance_types = ['full', 'tied', 'diag', 'spherical']\n",
    "\n",
    "for i in covariance_types:\n",
    "    #Define agglomerative clustering \n",
    "    gmm_cluster = GaussianMixture(n_components=2, random_state=123, covariance_type=i)\n",
    "\n",
    "    #Fit model\n",
    "    clusters = gmm_cluster.fit_predict(X_std)\n",
    "\n",
    "    ari = metrics.adjusted_rand_score(y, clusters)\n",
    "    sil_score = metrics.silhouette_score(X_std, clusters, metric='euclidean')\n",
    "    \n",
    "    print('covariance type: {}'.format(i))\n",
    "    print('adjusted rand index: {}'.format(ari))\n",
    "    print('silhouette score: {}'.format(sil_score))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARI score of covariance type spherical is higher than the others and its silhouette score is lower than the others. The scores of the other covariance types are the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
